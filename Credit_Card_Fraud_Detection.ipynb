{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a4d2d5",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4fb91",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "## Content\n",
    "\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87be463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faeb188c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71120ca5",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71ae94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6206c1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f33030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283726, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To remove any duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0d5668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of fraud transaction: 0.1667101358352777\n"
     ]
    }
   ],
   "source": [
    "fraud = data[data['Class']==1]\n",
    "normal = data[data['Class']==0]\n",
    "fraud_percentage = len(fraud)/len(data)*100\n",
    "print('Percentage of fraud transaction:',fraud_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff39c46",
   "metadata": {},
   "source": [
    "We can see that the percentage of fraud transaction is only 16.67% hence the dataset is highly unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be74bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94811.077600</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>88.472687</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47481.047891</td>\n",
       "      <td>1.948026</td>\n",
       "      <td>1.646703</td>\n",
       "      <td>1.508682</td>\n",
       "      <td>1.414184</td>\n",
       "      <td>1.377008</td>\n",
       "      <td>1.331931</td>\n",
       "      <td>1.227664</td>\n",
       "      <td>1.179054</td>\n",
       "      <td>1.095492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723909</td>\n",
       "      <td>0.724550</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.605627</td>\n",
       "      <td>0.521220</td>\n",
       "      <td>0.482053</td>\n",
       "      <td>0.395744</td>\n",
       "      <td>0.328027</td>\n",
       "      <td>250.399437</td>\n",
       "      <td>0.040796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54204.750000</td>\n",
       "      <td>-0.915951</td>\n",
       "      <td>-0.600321</td>\n",
       "      <td>-0.889682</td>\n",
       "      <td>-0.850134</td>\n",
       "      <td>-0.689830</td>\n",
       "      <td>-0.769031</td>\n",
       "      <td>-0.552509</td>\n",
       "      <td>-0.208828</td>\n",
       "      <td>-0.644221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228305</td>\n",
       "      <td>-0.542700</td>\n",
       "      <td>-0.161703</td>\n",
       "      <td>-0.354453</td>\n",
       "      <td>-0.317485</td>\n",
       "      <td>-0.326763</td>\n",
       "      <td>-0.070641</td>\n",
       "      <td>-0.052818</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.500000</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>-0.022248</td>\n",
       "      <td>-0.053468</td>\n",
       "      <td>-0.275168</td>\n",
       "      <td>0.040859</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029441</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>-0.011159</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>-0.052172</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.011288</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139298.000000</td>\n",
       "      <td>1.316068</td>\n",
       "      <td>0.800283</td>\n",
       "      <td>1.026960</td>\n",
       "      <td>0.739647</td>\n",
       "      <td>0.612218</td>\n",
       "      <td>0.396792</td>\n",
       "      <td>0.570474</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>0.595977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186194</td>\n",
       "      <td>0.528245</td>\n",
       "      <td>0.147748</td>\n",
       "      <td>0.439738</td>\n",
       "      <td>0.350667</td>\n",
       "      <td>0.240261</td>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>77.510000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean    94811.077600       0.005917      -0.004135       0.001613   \n",
       "std     47481.047891       1.948026       1.646703       1.508682   \n",
       "min         0.000000     -56.407510     -72.715728     -48.325589   \n",
       "25%     54204.750000      -0.915951      -0.600321      -0.889682   \n",
       "50%     84692.500000       0.020384       0.063949       0.179963   \n",
       "75%    139298.000000       1.316068       0.800283       1.026960   \n",
       "max    172792.000000       2.454930      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean       -0.002966       0.001828      -0.001139       0.001801   \n",
       "std         1.414184       1.377008       1.331931       1.227664   \n",
       "min        -5.683171    -113.743307     -26.160506     -43.557242   \n",
       "25%        -0.850134      -0.689830      -0.769031      -0.552509   \n",
       "50%        -0.022248      -0.053468      -0.275168       0.040859   \n",
       "75%         0.739647       0.612218       0.396792       0.570474   \n",
       "max        16.875344      34.801666      73.301626     120.589494   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  283726.000000  283726.000000  ...  283726.000000  283726.000000   \n",
       "mean       -0.000854      -0.001596  ...      -0.000371      -0.000015   \n",
       "std         1.179054       1.095492  ...       0.723909       0.724550   \n",
       "min       -73.216718     -13.434066  ...     -34.830382     -10.933144   \n",
       "25%        -0.208828      -0.644221  ...      -0.228305      -0.542700   \n",
       "50%         0.021898      -0.052596  ...      -0.029441       0.006675   \n",
       "75%         0.325704       0.595977  ...       0.186194       0.528245   \n",
       "max        20.007208      15.594995  ...      27.202839      10.503090   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean        0.000198       0.000214      -0.000232       0.000149   \n",
       "std         0.623702       0.605627       0.521220       0.482053   \n",
       "min       -44.807735      -2.836627     -10.295397      -2.604551   \n",
       "25%        -0.161703      -0.354453      -0.317485      -0.326763   \n",
       "50%        -0.011159       0.041016       0.016278      -0.052172   \n",
       "75%         0.147748       0.439738       0.350667       0.240261   \n",
       "max        22.528412       4.584549       7.519589       3.517346   \n",
       "\n",
       "                 V27            V28         Amount          Class  \n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000  \n",
       "mean        0.001763       0.000547      88.472687       0.001667  \n",
       "std         0.395744       0.328027     250.399437       0.040796  \n",
       "min       -22.565679     -15.430084       0.000000       0.000000  \n",
       "25%        -0.070641      -0.052818       5.600000       0.000000  \n",
       "50%         0.001479       0.011288      22.000000       0.000000  \n",
       "75%         0.091208       0.078276      77.510000       0.000000  \n",
       "max        31.612198      33.847808   25691.160000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad4c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deviation of amount column is huge as compared to other columns hence good to scale this variable\n",
    "amount = data['Amount'].values\n",
    "data['Amount'] = StandardScaler().fit_transform(amount.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2cd5564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the dependency on time of transaction\n",
    "f,(pt1, pt2) = plt.subplots(2, 1, sharex=True)\n",
    "pt1.scatter(fraud.Time, fraud.Amount)\n",
    "pt1.set_title('Fraud')\n",
    "pt2.scatter(normal.Time, normal.Amount)\n",
    "pt2.set_title('Normal')\n",
    "plt.xlabel('Time (in Seconds)')\n",
    "plt.ylabel('Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba20b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283726, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As fraud transaction distribution is almost similar over the time range, so good to drop the time column\n",
    "data.drop(['Time'], axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde8bf8",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "301ab628",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1).values\n",
    "y = data['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b704e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380296ef",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We will try with different machine learning models one by one.We can also tune\n",
    "these models by selecting optimized parameters, but if the accuracy is better \n",
    "even with less parameter tuning then no need to make it complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3a97593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor \n",
    "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b933344",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "640c704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test) # class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da5bcb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic regression model : 0.9991682174476963\n",
      "F1 Score of Logistic regression model : 0.6910994764397905\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score of Logistic regression model :',accuracy_score(y_test, lr_yhat))\n",
    "print('F1 Score of Logistic regression model :',f1_score(y_test, lr_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a815d",
   "metadata": {},
   "source": [
    "Accuracy score is almost 99.9% whereas F1 score is only 0.69 and it's \n",
    "obvious as the dataset is highly unbalanced thus F1-score is a better metric to \n",
    "evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36884a9e",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dad5b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_yhat = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3797f3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Support Vector Machine model : 0.8128342245989305\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score of Support Vector Machine model :',f1_score(y_test, svm_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed7d136",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2456d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 8)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_yhat = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3b2275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of K-Nearest Neighbors model : 0.8181818181818181\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score of K-Nearest Neighbors model :',f1_score(y_test, knn_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf63988",
   "metadata": {},
   "source": [
    "### Decistion Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45aa32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 5, criterion = 'entropy')\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_yhat = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "743161cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Decision Tree model : 0.781725888324873\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score of Decision Tree model :',f1_score(y_test, dtc_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75e61f",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d03c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91cb4394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Random forest model : 0.7434554973821991\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score of Random forest model :',f1_score(y_test, rf_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665b581",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b953b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed\\AnacondaN\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:06:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth = 4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c90e7eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of XGBoost model : 0.8585858585858586\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score of XGBoost model :',f1_score(y_test, xgb_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "159afaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70819,     3],\n",
       "       [   25,    85]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the confusion matrix\n",
    "confusion_matrix(y_test, xgb_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1191232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     70822\n",
      "           1       0.97      0.77      0.86       110\n",
      "\n",
      "    accuracy                           1.00     70932\n",
      "   macro avg       0.98      0.89      0.93     70932\n",
      "weighted avg       1.00      1.00      1.00     70932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report :\")\n",
    "print(classification_report(y_test,xgb_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1464cb",
   "metadata": {},
   "source": [
    "XGBoost has highest F1-score. We can improve accuracy by using deep learning \n",
    "algorithms or increasing more data for fraud cases and making it more balanced \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0195fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
